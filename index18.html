<!doctype html>
<html>
<head>
<script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs"></script>
<script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/posenet"></script>
<script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs-core"></script>
<script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs-converter"></script>
<script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs-backend-webgl"></script>
<script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/pose-detection"></script>
<script src="/js/app2.js"></script>
<script src="/js/tracker.js"></script>
</head>
<body>
    <select name="model" style="display: none;" id="model_select" class="form-control d-inline-block">
        <option value="MoveNetSinglePoseLightning">2D only (FAST) singlepose (faster) / MoveNet </option>
        <option value="MoveNetSinglePoseThunder">2D only (FAST) singlepose (slower) / MoveNet </option>
        <option value="MoveNetMultiPoseLightning">2D only (FAST) multipose / MoveNet</option>
        <option value="PoseNetMobileNetV1">2D only (SLOW) singlepose (faster) / PoseNet-MobileNetV1 </option>
        <option value="PoseNetResNet50">2D only (SLOW) singlepose (slower) / PoseNet-ResNet50</option>
        <option value="BlazePoseLite">2D + 3D singlepose (faster) / BlazePose</option>
        <option value="BlazePoseHeavy">2D + 3D singlepose (slower) / BlazePose</option>
        <option value="BlazePoseFull">2D + 3D singlepose (optimal) / BlazePose</option>
    </select>
    <!--<br>-->
<canvas style="background-color: black;" id="myCanvas" width="640" height="480"></canvas>
<canvas id="my-canvas" width="640" height="480"></canvas>
<script>
function playStream(canvas, stream) {
var video = document.createElement('video');
video.addEventListener('loadedmetadata', function() {
const context = canvas.getContext('2d');
var drawFrame = function() {
context.drawImage(video, 0, 0);
window.requestAnimationFrame(drawFrame);
};
drawFrame();
});
video.autoplay = true;
video.srcObject = stream;
}

function playCamera(canvas, preferedWidth, preferedHeight) {
var devices = navigator.mediaDevices;
if (devices && 'getUserMedia' in devices) {
var constraints = {
video: {
width: preferedWidth,
height: preferedHeight
}
};
var promise = devices.getUserMedia(constraints);
promise
.then(function(stream) {
playStream(canvas, stream);
})
.catch(function(error) {
console.error(error.name + ': ' + error.message);
});
} else {
console.error('Camera API is not supported.');
}
}


// Usage example:

var canvas = document.querySelector('#my-canvas');

playCamera(canvas, canvas.width, canvas.height);

var mediaSource = "/videos/9.mp4";

var muted = true;
var canvas = document.getElementById("myCanvas"); // get the canvas from the page
var ctx = canvas.getContext("2d");
var videoContainer; // object to hold video and associated info
var video = document.createElement("video"); // create a video element
video.src = mediaSource;
// the video will now begin to load.
// As some additional info is needed we will place the video in a
// containing object for convenience
video.autoPlay = false; // ensure that the video does not auto play
video.loop = false; // set the video to loop.
video.sound = 10;
videoContainer = {  // we will add properties as needed
video : video,
ready : false,   
};
// To handle errors. This is not part of the example at the moment. Just fixing for Edge that did not like the ogv format video
video.onerror = function(e){
document.body.removeChild(canvas);
document.body.innerHTML += "<h2>There is a problem loading the video</h2><br>";
document.body.innerHTML += "Users of IE9+ , the browser does not support WebM videos used by this demo";
document.body.innerHTML += "<br><a href='https://tools.google.com/dlpage/webmmf/'> Download IE9+ WebM support</a> from tools.google.com<br> this includes Edge and Windows 10";

}
video.oncanplay = readyToPlayVideo; // set the event to the play function that 
// can be found below
function readyToPlayVideo(event){ // this is a referance to the video
// the video may not match the canvas size so find a scale to fit
videoContainer.scale = Math.min(
canvas.width / this.videoWidth, 
canvas.height / this.videoHeight); 
videoContainer.ready = true;
// the video can be played so hand it off to the display function
requestAnimationFrame(updateCanvas);
// add instruction


}

function updateCanvas(){
ctx.clearRect(0,0,canvas.width,canvas.height); 
// only draw if loaded and ready
if(videoContainer !== undefined && videoContainer.ready){ 
// find the top left of the video on the canvas
// video.muted = muted;
var scale = videoContainer.scale;
var vidH = videoContainer.video.videoHeight;
var vidW = videoContainer.video.videoWidth;
var top = canvas.height / 2 - (vidH /2 ) * scale;
var left = canvas.width / 2 - (vidW /2 ) * scale;
// now just draw the video the correct size
ctx.drawImage(videoContainer.video, left, top, vidW * scale, vidH * scale);
if(videoContainer.video.paused){ // if not playing show the paused screen 
drawPayIcon();
}
}
// all done for display 
// request the next frame in 1/60th of a second
requestAnimationFrame(updateCanvas);
}

function drawPayIcon(){
ctx.fillStyle = "black";  // darken display
ctx.globalAlpha = 0.5;
ctx.fillRect(0,0,canvas.width,canvas.height);
ctx.fillStyle = "#DDD"; // colour of play icon
ctx.globalAlpha = 0.75; // partly transparent
ctx.beginPath(); // create the path for the icon
var size = (canvas.height / 2) * 0.5;  // the size of the icon
ctx.moveTo(canvas.width/2 + size/2, canvas.height / 2); // start at the pointy end
ctx.lineTo(canvas.width/2 - size/2, canvas.height / 2 + size);
ctx.lineTo(canvas.width/2 - size/2, canvas.height / 2 - size);
ctx.closePath();
ctx.fill();
ctx.globalAlpha = 1; // restore alpha
}    

function playPauseClick(){
if(videoContainer !== undefined && videoContainer.ready){
if(videoContainer.video.paused){                                 
videoContainer.video.play();
}else{
videoContainer.video.pause();
}
}
}

// register the event
canvas.addEventListener("click",playPauseClick);
</script>

<script>

    let source = 'camera'; // camera|video|stream		
    let sourceVideo = '';
    let defaultVideo = 'videos/10.mp4';
    let defaultStream = 'https://multiplatform-f.akamaihd.net/i/multi/will/bunny/big_buck_bunny_,640x360_400,640x360_700,640x360_1000,950x540_1500,.f4v.csmil/master.m3u8';
    let model = 'MoveNetSinglePoseLightning';
    /*
        ^^^ available pre-defined models:
            
            - MoveNetSinglePoseLightning				
            - MoveNetSinglePoseThunder
            - MoveNetMultiPoseLightning
            - PoseNetMobileNetV1
            - PoseNetResNet50
            - BlazePoseLite
            - BlazePoseHeavy
            - BlazePoseFull
     */

    // initialize app
    app.init();
    
    // initialize AI tracker model
    tracker.setModel(model);
    tracker.autofit = true; // enable auto resize/fit

    // set-up hooks
    tracker.on('statuschange', function(msg) {
        app.updateStatus(msg);
    });
    tracker.on('beforeupdate', function(poses) {
        app.updateDebug(poses);
        app.updateCounter(poses);
    });

    // config		
    tracker.elCanvas = '#myCanvas';
    tracker.elVideo = '#video';
    tracker.el3D = '#view_3d';
    tracker.pointWidth = 6;
    tracker.pointRadius = 8;

    // run predictions
    tracker.run(source);
</script>

</body>
</html>