<html>
<head>
    <style>
        /* Create two equal columns that floats next to each other */
.column {
  float: left;
  width: 50%;
  padding: 10px;
  height: 300px; /* Should be removed. Only for demonstration */
}
* {
  box-sizing: border-box;
  overflow-x: hidden;
}

/* Clear floats after the columns */
.row:after {
  content: "";
  display: table;
  clear: both;
}
    </style>
	<meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
	<title>JS AI Body Tracker v1.0.0</title>
	<link href="data:image/x-icon;base64,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"
          rel="icon" type="image/x-icon"/>
    <meta name="description"
          content="JS AI Body Tracker - javascript library implementing body tracking with ANN models: MoveNet, PoseNet and Blase Pose"/>
    <meta name="robots" content="index, follow"/>
    <meta name="og:site_name" content="JS AI Body Tracker"/>
    <meta name="og:type" content="website"/>
    <meta name="og:title" content="JS AI Body Tracker"/>
    <meta name="og:description"
          content="JS AI Body Tracker - javascript library implementing body tracking with ANN models: MoveNet, PoseNet and Blase Pose"/>
    <meta name="og:url" content="https://szczyglis.dev/js-ai-body-tracker"/>

	<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/css/bootstrap.min.css" integrity="sha384-zCbKRCUGaJDkqS1kPbPd7TveP5iyJE0EjAuZQTgFLD2ylzuqKfdKlfG/eSrtxUkn" crossorigin="anonymous">
	<link rel="stylesheet" href="/css/style2.css">	
	<link href="https://cdnjs.cloudflare.com/ajax/libs/video.js/7.0.0/video-js.css" rel="stylesheet">
    <script src="https://cdnjs.cloudflare.com/ajax/libs/video.js/7.0.0/video.min.js"></script>
</head>

<body>
	<div id="controls">
		<form method="GET">
			<div class="container">
				
			</div>
		</form>	

		<button id="btn_toggle_video" class="btn btn-secondary">VIDEO ON/OFF</button>

		<div id="video_src_area" style="display:none" class="text-center mt-3">
			<div class="container justify-content-center">
				<form class="form-horizontal" onsubmit="return false;">
					<div class="form-row justify-content-center">
					  	<div class="col-10 text-right">
					  		<div class="input-group mb-2">
						        <div class="input-group-prepend">
						          <div class="input-group-text">
						          	<span id="video_src_prefix"></span>
						          </div>
						      	</div>
					     	<input class="form-control" id="video_src" type="text" value="">
					     	</div>
					     </div>	
					     <div class="col-auto">
					      	<button id="btn_load_src" class="btn btn-primary">LOAD</button>
					     </div>	
					</div>
				</form>	
			</div>
			<div class="mt-2 text-center">
				<b>Tip:</b> click on "PLAY" icon to play or change video source URL and click "LOAD" button.
			</div>
		</div>
	</div>
	<button id="btn_toggle_controls" class="btn btn-primary">SHOW/HIDE CONTROLS</button>

	<div class="mt-2 text-center" id="status"></div>




    <div class="row">
        <div class="column" style="background-color:#000000; text-align: center; min-height: 800px;">
        			
                <canvas id="canvas"></canvas>
                <video id="video" class="video-js vjs-fluid vjs-default-skin" preload="metadata">
                    <source src="">
                </video>
            
        </div>
        <div class="column" style="background-color:#000000; min-height: 800px;">
          <!--  <canvas class="clip-polygon" id="vidcanvas"></canvas>-->
          <section id="demos" class="invisible">
            <div id="liveView" class="videoView">
               <button id="webcamButton" class="mdc-button mdc-button--raised">
                 <span class="mdc-button__ripple"></span>
                 <span class="mdc-button__label">ENABLE WEBCAM</span>
               </button>
               <div style="position: relative;">
                 <video id="webcam" style="width: 1280px; height: 720px; position: abso" autoplay playsinline></video>
                 <canvas class="output_canvas" id="output_canvas" width="1280" height="720" style="position: absolute; left: 0px; top: 0px;"></canvas>
               </div>
             </div>
           </section>
        </div>
      </div>
      

	<!-- Load Tensor Flow -->
	<script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs-core"></script>
	<script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs-converter"></script>
	<script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs-backend-webgl"></script>
	<script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/pose-detection"></script>

	<!-- Load tracker.js and app.js-->
	<script src="/js/app2.js"></script>
	<script src="/js/tracker2.js"></script>
	<script>

		let source = 'camera'; // camera|video|stream		
		let sourceVideo = '';
		let defaultVideo = '/videos/1.mp4';
		let model = 'MoveNetSinglePoseLightning';
		app.init();
		
		// initialize AI tracker model
		tracker.setModel(model);
		tracker.autofit = true; // enable auto resize/fit

		// set-up hooks
		tracker.on('statuschange', function(msg) {
			app.updateStatus(msg);
        });
		tracker.on('beforeupdate', function(poses) {
			app.updateDebug(poses);
			app.updateCounter(poses);
		});

		// config		
	    tracker.elCanvas = '#canvas';
	    tracker.pointWidth = 6;
    	tracker.pointRadius = 8;

		// run predictions
		tracker.run(source);

        function playStream(canvas, stream) {
        var video = document.createElement('video');
        video.addEventListener('loadedmetadata', function() {
        const context = canvas.getContext('2d');
        var drawFrame = function() {
        context.drawImage(video, 0, 0);
        window.requestAnimationFrame(drawFrame);
        };
        drawFrame();
        });
        video.autoplay = true; 
        video.srcObject = stream;
        }
        
        function playCamera(canvas, preferedWidth, preferedHeight) {
        var devices = navigator.mediaDevices;
        if (devices && 'getUserMedia' in devices) {
        var constraints = {
        video: {
        width: preferedWidth,
        height: preferedHeight
        }
        };
        var promise = devices.getUserMedia(constraints);
        promise
        .then(function(stream) {
        playStream(canvas, stream);
        })
        .catch(function(error) {
        console.error(error.name + ': ' + error.message);
        });
        } else {
        console.error('Camera API is not supported.');
        }
        }
        
        
        // Usage example:
        
        var canvas = document.querySelector('#vidcanvas');
        
        playCamera(canvas, canvas.width, canvas.height);
        
        var mediaSource = "/videos/9.mp4";
        
          
        function playPauseClick(){
        if(videoContainer !== undefined && videoContainer.ready){
        if(videoContainer.video.paused){                                 
        videoContainer.video.play();
        }else{
        videoContainer.video.pause();
        }
        }
        }
        
        // register the event
        canvas.addEventListener("click",playPauseClick);
        </script>

<script id="rendered-js" type="module">
    // Copyright 2023 The MediaPipe Authors.
    // Licensed under the Apache License, Version 2.0 (the "License");
    // you may not use this file except in compliance with the License.
    // You may obtain a copy of the License at
    //
    //      http://www.apache.org/licenses/LICENSE-2.0
    //
    // Unless required by applicable law or agreed to in writing, software
    // distributed under the License is distributed on an "AS IS" BASIS,
    // WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
    // See the License for the specific language governing permissions and
    // limitations under the License.
    import { PoseLandmarker, FilesetResolver, DrawingUtils } from "https://cdn.skypack.dev/@mediapipe/tasks-vision@0.10.0";
    const demosSection = document.getElementById("demos");
    let poseLandmarker = undefined;
    let runningMode = "IMAGE";
    let enableWebcamButton;
    let webcamRunning = false;
    const videoHeight = "360px";
    const videoWidth = "480px";
    // Before we can use PoseLandmarker class we must wait for it to finish
    // loading. Machine Learning models can be large and take a moment to
    // get everything needed to run.
    const createPoseLandmarker = async () => {
        const vision = await FilesetResolver.forVisionTasks("https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0/wasm");
        poseLandmarker = await PoseLandmarker.createFromOptions(vision, {
            baseOptions: {
                modelAssetPath: `https://storage.googleapis.com/mediapipe-models/pose_landmarker/pose_landmarker_lite/float16/1/pose_landmarker_lite.task`,
                delegate: "GPU"
            },
            runningMode: runningMode,
            numPoses: 2
        });
        demosSection.classList.remove("invisible");
    };
    createPoseLandmarker();
    /********************************************************************
    // Demo 1: Grab a bunch of images from the page and detection them
    // upon click.
    ********************************************************************/
    // In this demo, we have put all our clickable images in divs with the
    // CSS class 'detectionOnClick'. Lets get all the elements that have
    // this class.
    const imageContainers = document.getElementsByClassName("detectOnClick");
    // Now let's go through all of these and add a click event listener.
    for (let i = 0; i < imageContainers.length; i++) {
        // Add event listener to the child element whichis the img element.
        imageContainers[i].children[0].addEventListener("click", handleClick);
    }
    // When an image is clicked, let's detect it and display results!
    async function handleClick(event) {
        if (!poseLandmarker) {
            console.log("Wait for poseLandmarker to load before clicking!");
            return;
        }
        if (runningMode === "VIDEO") {
            runningMode = "IMAGE";
            await poseLandmarker.setOptions({ runningMode: "IMAGE" });
        }
        // Remove all landmarks drawed before
        const allCanvas = event.target.parentNode.getElementsByClassName("canvas");
        for (var i = allCanvas.length - 1; i >= 0; i--) {
            const n = allCanvas[i];
            n.parentNode.removeChild(n);
        }
        // We can call poseLandmarker.detect as many times as we like with
        // different image data each time. The result is returned in a callback.
        poseLandmarker.detect(event.target, (result) => {
            const canvas = document.createElement("canvas");
            canvas.setAttribute("class", "canvas");
            canvas.setAttribute("width", event.target.naturalWidth + "px");
            canvas.setAttribute("height", event.target.naturalHeight + "px");
            canvas.style =
                "left: 0px;" +
                    "top: 0px;" +
                    "width: " +
                    event.target.width +
                    "px;" +
                    "height: " +
                    event.target.height +
                    "px;";
            event.target.parentNode.appendChild(canvas);
            const canvasCtx = canvas.getContext("2d");
            const drawingUtils = new DrawingUtils(canvasCtx);
            for (const landmark of result.landmarks) {
                drawingUtils.drawLandmarks(landmark, {
                    radius: (data) => DrawingUtils.lerp(data.from.z, -0.15, 0.1, 5, 1)
                });
                drawingUtils.drawConnectors(landmark, PoseLandmarker.POSE_CONNECTIONS);
            }
        });
    }
    /********************************************************************
    // Demo 2: Continuously grab image from webcam stream and detect it.
    ********************************************************************/
    const video = document.getElementById("webcam");
    const canvasElement = document.getElementById("output_canvas");
    const canvasCtx = canvasElement.getContext("2d");
    const drawingUtils = new DrawingUtils(canvasCtx);
    // Check if webcam access is supported.
    const hasGetUserMedia = () => { var _a; return !!((_a = navigator.mediaDevices) === null || _a === void 0 ? void 0 : _a.getUserMedia); };
    // If webcam supported, add event listener to button for when user
    // wants to activate it.
    if (hasGetUserMedia()) {
        enableWebcamButton = document.getElementById("webcamButton");
        enableWebcamButton.addEventListener("click", enableCam);
    }
    else {
        console.warn("getUserMedia() is not supported by your browser");
    }
    // Enable the live webcam view and start detection.
    function enableCam(event) {
        if (!poseLandmarker) {
            console.log("Wait! poseLandmaker not loaded yet.");
            return;
        }
        if (webcamRunning === true) {
            webcamRunning = false;
            enableWebcamButton.innerText = "ENABLE PREDICTIONS";
        }
        else {
            webcamRunning = true;
            enableWebcamButton.innerText = "DISABLE PREDICTIONS";
        }
        // getUsermedia parameters.
        const constraints = {
            video: true
        };
        // Activate the webcam stream.
        navigator.mediaDevices.getUserMedia(constraints).then((stream) => {
            video.srcObject = stream;
            video.addEventListener("loadeddata", predictWebcam);
        });
    }
    let lastVideoTime = -1;
    async function predictWebcam() {
        canvasElement.style.height = videoHeight;
        video.style.height = videoHeight;
        canvasElement.style.width = videoWidth;
        video.style.width = videoWidth;
        // Now let's start detecting the stream.
        if (runningMode === "IMAGE") {
            runningMode = "VIDEO";
            await poseLandmarker.setOptions({ runningMode: "VIDEO" });
        }
        let startTimeMs = performance.now();
        if (lastVideoTime !== video.currentTime) {
            lastVideoTime = video.currentTime;
            poseLandmarker.detectForVideo(video, startTimeMs, (result) => {
                canvasCtx.save();
                canvasCtx.clearRect(0, 0, canvasElement.width, canvasElement.height);
                for (const landmark of result.landmarks) {
                    drawingUtils.drawLandmarks(landmark, {
                        radius: (data) => DrawingUtils.lerp(data.from.z, -0.15, 0.1, 5, 1)
                    });
                    drawingUtils.drawConnectors(landmark, PoseLandmarker.POSE_CONNECTIONS);
                }
                canvasCtx.restore();
            });
        }
        // Call this function again to keep predicting when the browser is ready.
        if (webcamRunning === true) {
            window.requestAnimationFrame(predictWebcam);
        }
    }
    //# sourceURL=pen.js
        </script>

</body>
</html>
